{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Association Mining\n",
    "\n",
    "In the first tutorial we looked at how Python can be used to do basic data exploration. I hope it was useful to you-- Python is one of the most in-demand skills for data scientists. There are some good reasons for this. The first one is that relying only on software will restrict you to the bounds of that software. By being able to program, you are not as restricted, and can do things that require complex logic.\n",
    "\n",
    "The second reason why a data scientist would want to learn Python is more theoretical. The Python programming language is designed to be highly portable, and as a result is one of the most versatile programming languages. Python hosts a large number of machine learning tools such as scikit-learn (machine learning), pandas (big data processing) and nltk (natural language processing), which do a lot of heavy lifting. Many of these features open new possibilities. We will explore one of them today by writing a simple association mining script using the same dataset as before.\n",
    "\n",
    "## About the Aipriori Algorithm\n",
    "\n",
    "The apriori association mining algorithm is a simple frequency item set mining algorithm, most commonly used to find associations over a transactional database. In the 1990s and early 2000s, this algorithm was used to discover a lot of data mining \"gems\" -- unexpected associations between purchases and behaviours. Today it is still commonly used by retailers and e-commerce companies to look at purchasing patterns. \n",
    "\n",
    "The algorithm looks at all of the transactions in a dataset and returns the most common associations between the items. It uses three measures: <i>support</i>, <i>confidence</i> and <i>lift</i>. Support describes the number of occurrences in the dataset. Confidence is how often the association is found to be true. Lift is the ratio of observed support to the independent observations of the items in the association. The wikipedia page gives a more detailed explanation: https://en.wikipedia.org/wiki/Association_rule_learning\n",
    "\n",
    "### Installing the Apyori Library\n",
    "\n",
    "Before we can get started, we will need to install the apyroi library. Yes, you read that right... aPYori. Python libraries often have letters \"py\" instead of \"pi\", just so you know that it is a PYthon library. If you haven't already, please type the following command in your Anaconda shell: \n",
    "\n",
    "<i>pip install apyori</i>\n",
    "\n",
    "This will install the necessary library. After that, we can get started as we did before by loading the dataset. Once again, we will load the csv file content and save it into the list <i>ec</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv #import the csv library for loading csv type files\n",
    "from apyori import apriori #import the apriori library\n",
    "\n",
    "ec = [] # we will declare a list to store the data\n",
    "\n",
    "with open('data.csv', newline='') as csvfile: #this is an expression used by the csv library to open the file\n",
    "    datareader = csv.reader(csvfile, delimiter=',', quotechar='|') #use the reader to read each row of the csv file and save as a list\n",
    "    for row in datareader: #this is a loop for iterating through each row\n",
    "        ec.append(row) #we will append the content of each row as row entry to the ec list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main differences from last time. You will notice that we <i>imported</i> the apyori library at the top of the script. This is how we bring outside libraries into our Python environment. Also, unlike last time, we will use the regular reader, instead of a DictReader. The apyori library prefers lists, instead of dictionaries. Using the regular csv reader, we will get results that are lists of lists. The practical difference for us is that we will have to select list items by specifying their numbers, instead of their key like last time.\n",
    "\n",
    "As before, it's usually a good practice to see what the string will print. If we run the following cell, we will get the output for the dataset that we loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ec[4]) #prints the fifth item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the apyori library is simple. We simply call then apriori function on the dataset and it will create a bunch of associations for us. Let's do that, while saving the associations as the \"associations\" list. Let's print it to see what the associations look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "associations = list(apriori(ec)) #use the apriori function to create associations\n",
    "\n",
    "print(associations) #print the associations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait! This is <u>not readable at all!</u>. By simply printing the list, we retrieved direct output from the associations. We can't use this on any sort of report! \n",
    "\n",
    "That said, we can sort of make out the details of the output. You can see the associations, support and confidence values. These are saved as lists within the list of associations. One way to manage this data is to only print the elements that we need, one by one. Let's loop through the results and only print the relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in associations: #loop through each association directly\n",
    "    #corresponds to the list values for association, the support and the confidence.\n",
    "    print(\"Association: \" + str(list(a[0])) + \", Support: \" + str(a[1]) + \", Confidence: \" + str(a[2][0][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better. However, it also revealed another problem. We only have 10 association rules.\n",
    "\n",
    "This was caused by the apriori functions default values. By default, it only collects support above 0.1. This is far too low for our dataset, as there is a lot of variance in the purchases. We can override the default by stating it in the function. Let's try lowering it to 0.002 ... patterns that happen at least 1000 times in our dataset (<u>warning: this may take about a minute to process on some computers</u>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "associations = list(apriori(ec, min_support=0.002)) #min support changed to 0.002\n",
    "print(len(associations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can once again look through these associations by looping and printing. Let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in associations:\n",
    "    print(\"Association: \" + str(list(a[0])) + \", Support: \" + str(a[1]) + \", Confidence: \" + str(a[2][0][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better still. If you scroll down, we see some interesting patterns start to emerge, such as:\n",
    "<ul>\n",
    "    <li>'United Kingdom', 'ASSORTED COLOUR BIRD ORNAMENT'</li>\n",
    "    <li>'United Kingdom', 'WHITE HANGING HEART T-LIGHT HOLDER'</li>\n",
    "    <li>'United Kingdom', '4.95', '47566', 'PARTY BUNTING'</li>\n",
    "</ul>\n",
    "Though interesting that some products are purchased from the UK at a certain price, it is clear that there is something missing. Typically, basket analysis is conducted <i>on baskets</i>. We seem to have output that is improperly structured for this task.\n",
    "\n",
    "One option is to restructure the data. Fortunately, we are using a programming language, so this step is relatively simple. We can create a simple script that creates a new list of baskets for association mining. The script below does this and finishes by reporting the number of basket associations produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "basket = [] #specify a list for basket items\n",
    "baskets = [] #a list of baskets\n",
    "invoice = ec[1][0] #a placeholder for the previous invoice number\n",
    "\n",
    "while i < len(ec): #iterate through each item sequentially\n",
    "    if ec[i][0] != invoice: #if this is a new invoice\n",
    "        baskets.append(basket) #append the baskets\n",
    "        basket = [] #start a new basket\n",
    "    basket.append(ec[i][2]) #add this item to basket\n",
    "    invoice = ec[i][0] #specify this current invoice as the new previous invoice\n",
    "    i += 1 #iterate to the next item\n",
    "\n",
    "len(baskets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can use the apriori function to create the associations and the print statement to print the results. Let's only print results that also have a confidence of greater than 50%, meaning that at least half of the time, these things are purchased together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "associations = list(apriori(baskets, min_support=0.02))\n",
    "\n",
    "for a in associations:\n",
    "    if a[2][0][2] > 0.5:\n",
    "        print(\"Association: \" + str(list(a[0])) + \", Support: \" + str(a[1]) + \", Confidence: \" + str(a[2][0][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much more powerful information. We can see that, for instance, that 'ROSES REGENCY TEACUP AND SAUCER ', 'GREEN REGENCY TEACUP AND SAUCER', 'PINK REGENCY TEACUP AND SAUCER' are <i>purchased together 85% of the time</i>! From the perspective of marketing, we could use this information to learn more about those customers and why they are purchasing so many saucers, and what are their motivations for doing so at that point in time.\n",
    "\n",
    "What other associations are out there? Feel free to play with the variables in this code to find new results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Question\n",
    "What happens when you change the confidence to 0.2? Do you think these less frequent associations are interesting to marketers?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
